{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIq-hks2NFgz"
      },
      "source": [
        "\n",
        "Lecture du Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJDqW3a0MNU1"
      },
      "outputs": [],
      "source": [
        "fichier = open(\"tales_dataset.txt\", \"r\")\n",
        "f=fichier.read()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugQWkdNpM1pB"
      },
      "source": [
        "Tri\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8h47duaOxBj"
      },
      "outputs": [],
      "source": [
        "txt=\"Bonjour mesdames, messieurs !\\n je m'appelle Hugues\"\n",
        "\n",
        "def tri(txt):\n",
        "  l=\"\"\n",
        "  for j in txt:\n",
        "    #for j in i:\n",
        "    if (j.isalpha() or j.isdigit() or j.isspace() or j==\"'\" or (j in ['.',',',';','!','?',':'])):\n",
        "      l+=j.lower()\n",
        "\n",
        "  #On enlève les sauts de ligne\n",
        "  b=l.replace('\\n',' ').split(' ')\n",
        "  c=[]\n",
        "  for i in b:\n",
        "    if i != \"\":\n",
        "      c.append(i)\n",
        "\n",
        "  #On sépare la ponctuation\n",
        "  cponc=[]\n",
        "  for i in c:\n",
        "    b=False\n",
        "    for k in ['.',',',';','!','?',':']:\n",
        "      if k in i:\n",
        "        if i[:-1]!='':\n",
        "          cponc.append(i[:-1])\n",
        "        cponc.append(k)\n",
        "        b=True\n",
        "        \n",
        "    if b==False:\n",
        "      cponc.append(i)\n",
        "\n",
        "  \n",
        "  return cponc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61XKWm9nTkB-"
      },
      "source": [
        "Préparation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np6hRaGRTmNB"
      },
      "outputs": [],
      "source": [
        "L=tri(f)\n",
        "memo=50\n",
        "M=[]\n",
        "N=[]\n",
        "for i in range(len(L)-memo):\n",
        "  M.append(L[i:i+memo])\n",
        "  N.append(L[i+memo])\n",
        "Mr=M\n",
        "Nr=N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUNUgJ1qWFNF"
      },
      "source": [
        "Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnAtzMywWIT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97dde53c-61c1-4a1e-c119-793fc90e23e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47064\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "t=Tokenizer(filters='')\n",
        "\n",
        "t.fit_on_texts(L)\n",
        "\n",
        "len_dict=len(t.word_index)\n",
        "print(len_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcSrtl-tZ1-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e931dbac-247c-4df2-9a23-a3cf5442cb20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[420]\n",
            "[6, 26126, 4, 34, 11, 26127, 1, 246, 1, 21, 58, 2203, 9, 575, 2, 106, 9030, 4, 30, 426, 14, 10, 1931, 377, 43, 13, 157, 226, 117, 33, 346, 5, 1045, 4612, 3, 13, 42, 117, 685, 53, 21, 5, 33, 26, 3, 221, 4, 42, 2, 106]\n"
          ]
        }
      ],
      "source": [
        "lenMr=len(Mr)\n",
        "c=round(0.8*lenMr)\n",
        "\n",
        "Mrs = t.texts_to_sequences(Mr)\n",
        "Nrs = t.texts_to_sequences(Nr)\n",
        "\n",
        "data_trains=Mrs[:c]\n",
        "data_valids=Mrs[c:]\n",
        "label_train=Nrs[:c]\n",
        "label_valid=Nrs[c:]\n",
        "#import tensorflow as tf\n",
        "\n",
        "#label_train = tf.keras.utils.to_categorical(Nrs[:c],len_dict)\n",
        "#label_valid = tf.keras.utils.to_categorical(Nrs[c:],len_dict)\n",
        "print(label_train[0])\n",
        "print(Mrs[111668])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycc2stxumD3g"
      },
      "source": [
        "Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDNVBUbdmEvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e91017e-eda2-4ae4-ec69-fe2a96773689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 15)            705975    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10)                1040      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                352       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 47064)             1553112   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,261,535\n",
            "Trainable params: 2,261,535\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras import models,layers\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "i = layers.Input(shape=(memo,))\n",
        "model = models.Sequential()\n",
        "model.add(i)\n",
        "model.add(layers.Embedding(len_dict+1,15))\n",
        "model.add(layers.LSTM(10,return_sequences=False))\n",
        "model.add(layers.Dense(32,activation=\"relu\"))\n",
        "model.add(layers.Dense(32,activation=\"relu\"))\n",
        "model.add(layers.Dense(len_dict,activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-SoiQcinymB"
      },
      "source": [
        "Compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky9bXK0lnz54"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss=keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VazQrX-Mn5GN",
        "outputId": "3474c2fc-1509-4435-a76e-8edb944a84ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "268162/268162 [==============================] - 2582s 10ms/step - loss: 5.7200 - accuracy: 0.1805 - val_loss: nan - val_accuracy: 0.1536\n",
            "Epoch 2/5\n",
            "268162/268162 [==============================] - 2541s 9ms/step - loss: 5.6282 - accuracy: 0.1808 - val_loss: nan - val_accuracy: 0.1512\n",
            "Epoch 3/5\n",
            "202785/268162 [=====================>........] - ETA: 8:58 - loss: 5.5141 - accuracy: 0.1811"
          ]
        }
      ],
      "source": [
        "model.fit(x=data_trains,y=label_train,batch_size=8,epochs=5,validation_data=(data_valids,label_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFAtdD1sx61I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "e35a4745-b097-41a7-ca7e-66f86bb97d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "91\n",
            "142\n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "92\n",
            "143\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "93\n",
            "144\n",
            "3/3 [==============================] - 0s 12ms/step\n",
            "94\n",
            "145\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "95\n",
            "146\n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "96\n",
            "147\n",
            "4/4 [==============================] - 0s 23ms/step\n",
            "97\n",
            "148\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "98\n",
            "149\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "99\n",
            "150\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Lovely Ilonka There was once a king's son who told his father that he wished to marry. 'No, no!' said the king; 'you must not be in such a hurry. Wait till you have done some great deed. My father did not let me marry till I had won the golden sword you see me wear.' The prince was much disappointed, but he never dreamed of disobeying his father, and he began to think with all his might what he could do. Yes, indeed, I've lived long and been much about in the world, but I have never seen or heard anything of what you ask. Still, if you will wait till to-morrow I may be able to tell you something. Well, he waited on of and and moment and the and are and\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\n",
        "def generationv1(phrase):\n",
        "  tri_p=tri(phrase)\n",
        "  seq_p=t.texts_to_sequences(tri_p)\n",
        "  memo=50\n",
        "  Mp=[]\n",
        "  for i in range(len(seq_p)-memo):\n",
        "    Mp.append(seq_p[i:i+memo])\n",
        "  print(len(tri_p))\n",
        "  res = model.predict(Mp)\n",
        "  print(len(res))\n",
        "  i=len(res)-1\n",
        "  a = max(res[i])\n",
        "  ind = list(res[i]).index(a)\n",
        "  ttt = t.word_index\n",
        "  b=list(ttt.keys())[ind]\n",
        "  return b\n",
        "\n",
        "def generationv2(phrase):\n",
        "  phr=phrase\n",
        "  for i in range(10):\n",
        "    phr=phr+' '+generationv1(phr)\n",
        "  return phr\n",
        "generationv2(\"Lovely Ilonka There was once a king's son who told his father that he wished to marry. 'No, no!' said the king; 'you must not be in such a hurry. Wait till you have done some great deed. My father did not let me marry till I had won the golden sword you see me wear.' The prince was much disappointed, but he never dreamed of disobeying his father, and he began to think with all his might what he could do. Yes, indeed, I've lived long and been much about in the world, but I have never seen or heard anything of what you ask. Still, if you will wait till to-morrow I may be able to tell you something. Well, he waited\")\n",
        "#generation(\"Yes, indeed, I've lived long and been much about in the world, but I have never seen or heard anything of what you ask. Still, if you will wait till to-morrow I may be able to tell you something.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpGW7Hme1OW3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}